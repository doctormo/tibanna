{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from dcicutils import ff_utils\n",
    "from core.utils import run_workflow\n",
    "from datetime import datetime\n",
    "from core.wfr import *\n",
    "\n",
    "env = 'data'\n",
    "tibanna = Tibanna(env=env)\n",
    "\n",
    "ff = ff_utils.fdn_connection(key={\"default\" : tibanna.ff_keys})\n",
    "exclude_miseq = True\n",
    "\n",
    "# auth = ff_utils.get_authentication_with_server({},env)\n",
    "# print auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 total number of sets\n",
      "66 sets completed\n",
      "\n",
      "1 4DNES1QUXG92\n",
      "MboI mouse\n",
      "4DNEX4J4Z9WE part1 complete\n",
      "4DNEX4J4Z9WE part2 complete\n",
      "4DNEXRI9JYW6 part1 complete\n",
      "4DNEXRI9JYW6 part2 complete\n",
      "4DNES1QUXG92 is missing Part3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "step_settings() takes exactly 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-117b5ff7c80d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0minp_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'input_pairs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mset_pairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chromsizes'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchrsize_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'restriction_file'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0menz_ref\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mrun_missing_wfr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morganism\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtibanna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m#####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: step_settings() takes exactly 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "out_n = \"This is an output file of the Hi-C processing pipeline\"\n",
    "int_n = \"This is an intermediate file in the HiC processing pipeline\"\n",
    "\n",
    "def step_settings(seq, my_organism, lab):\n",
    "    genome = \"\"\n",
    "    mapper = {'human':'GRCh38','mouse':'GRCm38'}\n",
    "    genome = mapper.get(my_organism)\n",
    "    \n",
    "    wf_dict =[{\n",
    "        'wf_name': 'bwa-mem',\n",
    "        'wf_uuid': '3feedadc-50f9-4bb4-919b-09a8b731d0cc',\n",
    "        'parameters': {\"nThreads\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'out_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'intermediate file',\n",
    "                'description': int_n,\n",
    "                'contributing_labs': [lab,]}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-bam',\n",
    "        'wf_uuid': '023bfb3e-9a8b-42b9-a9d4-216079526f68',\n",
    "        'parameters': {\"nthreads_merge\": 16, \"nthreads_parse_sort\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'annotated_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'alignment',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]},\n",
    "            'filtered_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-replicate',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-pairs',\n",
    "        'wf_uuid': 'c9e0e6f7-b0ed-4a42-9466-cadc2dd84df0',\n",
    "        'parameters': {\"nthreads\": 1, \"maxmem\": \"32g\"},\n",
    "        'custom_pf_fields': {\n",
    "            'cooler_normvector': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'juicebox norm vector',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]},\n",
    "            'hic': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]},\n",
    "            'mcool': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]},\n",
    "            'merged_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-combined',\n",
    "                'description': out_n,\n",
    "                'contributing_labs': [lab,]}\n",
    "        }}]\n",
    "    \n",
    "    return wf_dict[seq]\n",
    "  \n",
    "    \n",
    "# url for hic exps\n",
    "exp_types = ['in%20situ%20Hi-C', 'dilution%20Hi-C']\n",
    "set_url = '/search/?'+'&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+ \\\n",
    "          '&type=ExperimentSetReplicate&limit=all'\n",
    "run_sets = ff_utils.search_metadata(set_url , ff_env=env)\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = True\n",
    "\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "all_sets = len(run_sets)\n",
    "print(str(all_sets)+' total number of sets')\n",
    "\n",
    "run_sets = [i for i in run_sets if \"HiC_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "\n",
    "print(str(all_sets-len(run_sets))+ ' sets completed')\n",
    "\n",
    "\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "    print\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size = find_pairs(a_set, exclude_miseq, env, tibanna)\n",
    "    # skip some cases\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print counter, a_set['accession'], organism, enzyme, 'skipping set with not chrsize/bwa index'\n",
    "        continue\n",
    "    if not enz_ref:\n",
    "        print counter, a_set['accession'], 'skipping not ready NZ', organism, enzyme\n",
    "        continue\n",
    "    if f_size < 15:\n",
    "        print counter, a_set['accession'], 'skipping small file size', str(f_size) \n",
    "        continue\n",
    "    print counter, a_set['accession']\n",
    "    print enzyme, organism\n",
    "    part3 = 'done'\n",
    "    list_release = []\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            bam1 = get_wfr_out(pair[0], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            bam2 = get_wfr_out(pair[1], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            # if run is not successful\n",
    "            if bam1.startswith('no') or not bam1 or bam1 != bam2:\n",
    "                part1 = 'not ready'\n",
    "                if add_wfr:\n",
    "                    if not bwa_index:\n",
    "                        print 'not yet usable', organism\n",
    "                        continue\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings(0, organism), inp_f, name_tag, env, tibanna)\n",
    "            elif bam1 == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                exp_bams.append(bam1)\n",
    "                list_release.append(bam1)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print exp, 'has missing Part1 runs'\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print exp, 'part1 complete'\n",
    "        #check if part 2 is run already, it not start the run\n",
    "        exp_com_bam = []\n",
    "        exp_pairs = []\n",
    "        for bam in exp_bams:\n",
    "            com_bam = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'bam', env)\n",
    "            pairs = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'pairs', env)\n",
    "            # try to run if missing\n",
    "            if pairs.startswith('no') or not pairs:\n",
    "                part2 = 'not ready'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            elif pairs == 'running':\n",
    "                print(bam)\n",
    "                part2 = 'still running'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            else:\n",
    "                exp_com_bam.append(com_bam)\n",
    "                exp_pairs.append(pairs)\n",
    "                \n",
    "        # if still running, skip to next experiment\n",
    "        if part2 == 'still running':\n",
    "            print('part2 still running')\n",
    "            continue\n",
    "        \n",
    "        # make sure all bams went through the same wfr and produces same file\n",
    "        if part2 != 'done' or len(list(set(exp_com_bam))) != 1 or len(list(set(exp_pairs))) !=1:\n",
    "            print exp, 'Part2 did not complete'\n",
    "            part3 = 'not ready' \n",
    "        \n",
    "            if add_wfr:\n",
    "                if not chrsize_ref:\n",
    "                    print 'not yet usable', organism\n",
    "                    continue\n",
    "                # make sure no duplicates\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings(1, organism), inp_f, exp, env, tibanna)   \n",
    "            continue\n",
    "            \n",
    "        # add bam and pairs to exp proc file\n",
    "        list_release.extend([exp_com_bam[0],exp_pairs[0]])\n",
    "        if add_pc:\n",
    "            add_processed_files(exp, [exp_com_bam[0],exp_pairs[0]], env)\n",
    "        \n",
    "        print exp, 'part2 complete'\n",
    "        set_pairs.append(exp_pairs[0])\n",
    "    \n",
    "    if part3 != 'done':\n",
    "        print 'Part3 not ready'\n",
    "        continue\n",
    "    \n",
    "    if not set_pairs:\n",
    "        print 'no pairs can be produced from this set'\n",
    "        continue\n",
    "        \n",
    "    merged_pairs = []\n",
    "    for set_pair in set_pairs:\n",
    "        merged_pair = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'pairs', env)\n",
    "        hic = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'hic', env)\n",
    "        mcool = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'mcool', env)\n",
    "        normvec = get_wfr_out(set_pair, 'hi-c-processing-pairs 0.2.5', 'normvector_juicerformat', env)\n",
    "        if merged_pair.startswith('no') or not merged_pair:\n",
    "            part3 = 'not ready'\n",
    "            break\n",
    "        elif merged_pair == 'running':\n",
    "            part3 = 'still running'\n",
    "            break\n",
    "        else:\n",
    "            merged_pairs.append(merged_pair)\n",
    "    \n",
    "    \n",
    "    # if part3 is still running report it, and skip the rest of the script\n",
    "    if part3 == 'still running':\n",
    "        print 'part3', part3\n",
    "        continue        \n",
    "                \n",
    "    if part3 != 'done' or len(list(set(merged_pairs))) != 1:\n",
    "        print a_set['accession'], 'is missing Part3'\n",
    "        \n",
    "        # if it is not run, and add_wfr is true, go for it, then skip the rest of the script\n",
    "        if add_wfr:\n",
    "            if not chrsize_ref:\n",
    "                print 'not yet usable', organism\n",
    "                continue\n",
    "\n",
    "            if not enz_ref:\n",
    "                print 'restriction enzyme not ready for', organism, enzyme\n",
    "                continue\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref, 'restriction_file': enz_ref} \n",
    "            run_missing_wfr(step_settings(2, organism), inp_f, a_set['accession'], env, tibanna)\n",
    "        continue\n",
    "    #####\n",
    "    #add competed flag to experiment\n",
    "    if add_pc and add_rel:\n",
    "        ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'] , ff_env=env)\n",
    "    \n",
    "    # add processed files to set\n",
    "    list_release.extend([merged_pair, hic, mcool, normvec])\n",
    "    if add_pc:\n",
    "        add_processed_files(a_set['accession'], [merged_pair, hic, mcool, normvec], env)\n",
    "    \n",
    "    #release files and wfrs\n",
    "    if add_rel:\n",
    "        release_files(a_set['accession'], list(set(list_release)), env)\n",
    "    \n",
    "    completed += 1\n",
    "    completed_acc.append(a_set['accession'])\n",
    "    print a_set['accession'], 'part3 complete'\n",
    "\n",
    "    \n",
    "print completed\n",
    "print completed_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "95 total number of sets\n",
    "66 sets completed\n",
    "\n",
    "1 4DNES1QUXG92\n",
    "MboI mouse\n",
    "4DNEX4J4Z9WE part1 complete\n",
    "4DNEX4J4Z9WE part2 complete\n",
    "4DNEXRI9JYW6 part1 complete\n",
    "4DNEXRI9JYW6 part2 complete\n",
    "4DNES1QUXG92 is missing Part3\n",
    "\n",
    "2 4DNESWDLDMGN\n",
    "MboI mouse\n",
    "4DNEXA7ZMMK3 part1 complete\n",
    "4DNEXA7ZMMK3 part2 complete\n",
    "4DNEXVGS8FQQ part1 complete\n",
    "4DNEXVGS8FQQ part2 complete\n",
    "4DNESWDLDMGN is missing Part3\n",
    "\n",
    "3 4DNESQMM4EBN\n",
    "MboI mouse\n",
    "4DNEXU87YSSY part1 complete\n",
    "4DNEXU87YSSY part2 complete\n",
    "4DNEXLWC9JX7 part1 complete\n",
    "4DNEXLWC9JX7 part2 complete\n",
    "4DNESQMM4EBN is missing Part3\n",
    "\n",
    "4 4DNESKKSKG7Y\n",
    "MboI mouse\n",
    "4DNEXB65W9GS part1 complete\n",
    "4DNEXB65W9GS part2 complete\n",
    "4DNEXNT6XXHX has missing Part1 runs\n",
    "Part3 not ready\n",
    "\n",
    "(u'/files-fastq/4DNFI4O4CPDH/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFICUHBSN5/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFI6MXCEPW/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIEWPBMCR/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIHUVBRKH/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIPIVCJCP/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIJEUX4GL/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIOGYWJTW/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIIMOII76/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFI4J8WZZU/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFI4HMA9X6/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIJ5ILLUG/', 'does not have a pair')\n",
    "5 4DNESQEND1X5 skipping small file size 0\n",
    "\n",
    "(u'/files-fastq/4DNFIA461Y3W/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIPKJQVNX/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIX3EAAM5/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIENL1TT3/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIEMD37BR/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFI1H7FBSD/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIQHRGDWB/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIWUHSWJZ/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIXGR9HO7/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIAUFS4OS/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIO2LPCU7/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIHQCPQIU/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIFEJNUNM/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIGWRLEZK/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFILGWLYRC/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIS4FORWQ/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFIG1WOWVE/', 'does not have a pair')\n",
    "(u'/files-fastq/4DNFICXZS411/', 'does not have a pair')\n",
    "6 4DNESKHB7GPW skipping small file size 1\n",
    "\n",
    "7 4DNESH4UTRNL\n",
    "DpnII mouse\n",
    "4DNEX4KRGMAQ part1 complete\n",
    "/files-processed/4DNFIZ32E4IH/\n",
    "/files-processed/4DNFIC2GWTU7/\n",
    "/files-processed/4DNFIV1M1SN8/\n",
    "/files-processed/4DNFIEMLVQQK/\n",
    "/files-processed/4DNFI537T8V6/\n",
    "part2 still running\n",
    "4DNEXOHPSJTN part1 complete\n",
    "4DNEXOHPSJTN part2 complete\n",
    "Part3 not ready\n",
    "\n",
    "8 4DNESNYBDSLY\n",
    "DpnII mouse\n",
    "4DNEXDSNPZOU part1 complete\n",
    "4DNEXDSNPZOU part2 complete\n",
    "4DNEXH1YN2XB part1 complete\n",
    "4DNEXH1YN2XB part2 complete\n",
    "4DNESNYBDSLY part3 complete\n",
    "\n",
    "9 4DNES54YB6TQ\n",
    "DpnII mouse\n",
    "4DNEXMM7MN7V part1 complete\n",
    "4DNEXMM7MN7V part2 complete\n",
    "4DNEXBSGTVWJ part1 complete\n",
    "4DNEXBSGTVWJ part2 complete\n",
    "4DNES54YB6TQ part3 complete\n",
    "\n",
    "10 4DNES4DGHDMX\n",
    "NcoI human\n",
    "4DNEXX13N3PT part1 complete\n",
    "4DNEXX13N3PT part2 complete\n",
    "4DNES4DGHDMX is missing Part3\n",
    "\n",
    "11 4DNES6V4HVDE skipping small file size 14\n",
    "\n",
    "12 4DNESEYETNMX skipping small file size 0\n",
    "\n",
    "13 4DNESX29AMHF skipping small file size 0\n",
    "\n",
    "14 4DNESAZ12B8V skipping small file size 0\n",
    "\n",
    "15 4DNESE9NXACG skipping small file size 0\n",
    "\n",
    "16 4DNES4JNDDVX skipping small file size 0\n",
    "\n",
    "17 4DNESDP9ECMN skipping small file size 0\n",
    "\n",
    "18 4DNES21VTCK2 skipping small file size 0\n",
    "\n",
    "19 4DNESJNPEKZD skipping small file size 0\n",
    "\n",
    "20 4DNESETP2XUO skipping small file size 0\n",
    "\n",
    "21 4DNESCI5VSPV skipping small file size 0\n",
    "\n",
    "22 4DNES3RHDBBR skipping small file size 1\n",
    "\n",
    "23 4DNESZ2PVZWR skipping small file size 0\n",
    "\n",
    "24 4DNESSCS4D46 skipping small file size 0\n",
    "\n",
    "25 4DNESBJ1KYYH skipping small file size 9\n",
    "\n",
    "26 4DNESGW9DHH3 skipping not ready NZ human MspI\n",
    "\n",
    "27 4DNESXTSP7H7 skipping not ready NZ human NcoI_MspI_BspHI\n",
    "\n",
    "28 4DNES6YMW2WC skipping not ready NZ mouse HindIII\n",
    "\n",
    "29 4DNESNZZR2VD\n",
    "HindIII human\n",
    "4DNEXVHF97YT part1 complete\n",
    "4DNEXVHF97YT part2 complete\n",
    "4DNEX17F64JD part1 complete\n",
    "4DNEX17F64JD part2 complete\n",
    "(u'4DNEX5SKVSJX', 'does not have any fastq pairs')\n",
    "4DNEXJ78M1F7 part1 complete\n",
    "4DNEXJ78M1F7 part2 complete\n",
    "4DNESNZZR2VD is missing Part3\n",
    "2\n",
    "[u'4DNESNYBDSLY', u'4DNES54YB6TQ']\n",
    "\n",
    "â€‹"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
